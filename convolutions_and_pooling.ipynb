{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "convolutions_and_pooling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMw4wG131LCMqUaemKjKEsg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SohaHussain/Neural-Networks-and-Deep-Learning/blob/main/convolutions_and_pooling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EeLE5ySKhrz"
      },
      "source": [
        "Convolutions narrow down the content to focus on specific , distinct details.\n",
        "That's the concept of Convolutional Neural Networks. Add some layers to do convolution before you have the dense layers, and then the information going to the dense layers is more focussed, and possibly more accurate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zIsK71MIBL9"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRK4iFzwLzC_"
      },
      "source": [
        "# loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTNyDd6ILH4K",
        "outputId": "f84896fb-85a0-4c86-88ce-9d77d6d4c917"
      },
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels) , (test_images,test_labels) = mnist.load_data()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuhuLzxuMAY9"
      },
      "source": [
        "#normalizing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNHDGGLbLwdI"
      },
      "source": [
        "training_images = training_images.reshape(60000,28,28,1)\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images.reshape(10000,28,28,1)\n",
        "test_images = test_images/255.0"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6s8VwMFNf_2"
      },
      "source": [
        "the training data needed to be reshaped, that's because the first convolution expects a single tensor containing everything, so instead of 60,000 28x28x1 items in a list, we have a single 4D list that is 60,000x28x28x1, and the same for the test images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dersOJCuOA4B"
      },
      "source": [
        "#defining model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_T4laWbNZH_"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "                                   tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28,28,1)),\n",
        "                                   tf.keras.layers.MaxPooling2D(2,2),\n",
        "                                   tf.keras.layers.Conv2D(64, (3,3), activation = 'relu'),\n",
        "                                   tf.keras.layers.MaxPooling2D(2,2),\n",
        "                                   tf.keras.layers.Flatten(),\n",
        "                                   tf.keras.layers.Dense(128, activation='relu'),\n",
        "                                   tf.keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--6aOeoRPdKS"
      },
      "source": [
        "following the Convolution with a MaxPooling layer which is then designed to compress the image, while maintaining the content of the features that were highlighted by the convlution. By specifying (2,2) for the MaxPooling, the effect is to quarter the size of the image. Without going into too much detail here, the idea is that it creates a 2x2 array of pixels, and picks the biggest one, thus turning 4 pixels into 1. It repeats this across the image, and in so doing halves the number of horizontal, and halves the number of vertical pixels, effectively reducing the image by 25%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xK8A2TuPWhR",
        "outputId": "f5326eb7-232f-45e2-87c4-4b6d82c3e919"
      },
      "source": [
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               204928    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 243,786\n",
            "Trainable params: 243,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RumQY0nKQtak",
        "outputId": "a04ac1e2-873c-4f0e-87ec-b71d605f6456"
      },
      "source": [
        "model.fit(training_images,training_labels,epochs=5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 77s 40ms/step - loss: 2.3028 - accuracy: 0.0985\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 75s 40ms/step - loss: 2.3028 - accuracy: 0.0984\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 75s 40ms/step - loss: 2.3028 - accuracy: 0.0983\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 75s 40ms/step - loss: 2.3028 - accuracy: 0.0997\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 75s 40ms/step - loss: 2.3028 - accuracy: 0.0997\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f120ea48890>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6iT1JEjQ7Ea",
        "outputId": "9beca470-fa5d-44c3-88db-b519b4e1a607"
      },
      "source": [
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 4s 11ms/step - loss: 2.2910 - accuracy: 0.1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KS0GHA-CScqN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}